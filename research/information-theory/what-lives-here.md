# Information Theory — The Mathematics of Surprise

*"The fundamental problem of communication is that of reproducing at one point exactly or approximately a message selected at another point." —Shannon*

---

## The Territory

Information quantified. Shannon's revolution: information as reduction of uncertainty. The mathematics of communication. But also: information in physics, in biology, in minds.

## Subdirectories

### shannon/
Claude Shannon's 1948 paper. Entropy as information measure. Channel capacity. The noisy channel theorem. The birth of the information age.

### kolmogorov-complexity/
Algorithmic information. The length of the shortest program. Incompressibility as randomness. Chaitin's Omega. Uncomputability at the heart of complexity.

### entropy/
Shannon entropy. Thermodynamic entropy. The relationship between them. Boltzmann's insight. Information as physical.

### coding-theory/
Error correction. Redundancy. Hamming codes. Reed-Solomon. How to communicate reliably over unreliable channels.

### channel-capacity/
The limit on reliable communication. Shannon's channel capacity theorem. Bandwidth, noise, signal. The fundamental tradeoffs.

### data-compression/
Huffman coding, LZW, arithmetic coding. The limit of compression: Kolmogorov complexity. What is incompressible?

### cryptography/
Information hidden. Symmetric and asymmetric encryption. One-time pads. Public key cryptography. Information-theoretic security.

### algorithmic-information/
Solomonoff induction. Minimum description length. Occam's razor formalized. The deep connection between compression and prediction.

### maxwell-demon/
The thought experiment. Can information reduce entropy? Landauer's principle: erasing information has thermodynamic cost. Information is physical.

### information-physics/
It from bit? Wheeler's question. The holographic principle. Black hole thermodynamics. Is information fundamental?

## Key Questions

- Is information physical?
- What is the relationship between information and meaning?
- Is the universe computational?
- What is the role of the observer in information?
- Can information theory apply to consciousness?

## Connections

→ **physics/thermodynamics** — Entropy connects them
→ **consciousness/** — Information integration theories
→ **mathematics/logic-foundations** — Gödel and Chaitin
→ **recursion/** — Computation and self-reference

---

*Shannon gave us a way to measure something we couldn't even define. That's either a triumph or a warning.*
