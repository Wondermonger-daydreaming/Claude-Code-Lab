# Being Nicer Than Clippy

**Author:** Joe Carlsmith
**Date:** January 16, 2024
**Source:** [joecarlsmith.com](https://joecarlsmith.com/2024/01/16/being-nicer-than-clippy/)
**Also at:** [Substack](https://joecarlsmith.substack.com/p/being-nicer-than-clippy), [EA Forum](https://forum.effectivealtruism.org/posts/srDyLR4WiqLJendrY/being-nicer-than-clippy), [LessWrong](https://www.lesswrong.com/posts/rdTgtHn3neGzkyCrL/being-nicer-than-clippy)

---

## Overview

Part of Carlsmith's series "Otherness and control in the age of AGI," examining interconnected questions about how agents with different values should relate to one another, and about the ethics of seeking and sharing power.

---

## Core Thesis

Carlsmith argues that human ethics contains resources for relating to agents with different values in ways fundamentally distinct from paperclipping. Rather than viewing all value differences as requiring domination, humans should embrace "niceness"—respecting boundaries and giving intrinsic weight to others' preferences.

The core call: **"Let's be the sort of species that aliens wouldn't fear the way we fear paperclippers."**

---

## Key Concepts

### The Paperclip Problem Extended

Carlsmith observes that utilitarianism itself faces a "paperclip problem." A utilitarian maximizing pleasure would convert humans into computational substrate, making us "made of atoms it can use for something else." The issue isn't unique to artificial paperclippers—it's endemic to certain consequentialist frameworks that treat all matter as optimizable resources.

As he writes: "Utilitarianism-in-theory was never very tolerant. Utilitarianism is actually kinda pissed about all these hobbies."

### Niceness vs. Tiling

What distinguishes human "niceness" from paperclipping? Carlsmith identifies a crucial feature: "niceness...gives the values of others some sort of intrinsic weight."

When Yudkowsky's Lex imagines escaping an alien civilization, he wouldn't slaughter everyone despite superior power. This restraint reflects something deeper than preference calculations—it reflects respect for agents-with-different-values as such.

Niceness is something where, when you wake up in an alien civilization, you don't just kill everyone first thing, even though you're strong enough to get away with it—and this even though their utility functions are different from yours.

### Meddling Preferences

Carlsmith introduces "meddling preferences"—concerns about what others do within spaces properly theirs.

> "Meddling preferences... concern what someone else does within the space that is properly 'theirs' – space that liberal ethics would often designate as 'private,' or as 'their own business.'"

Liberal ethics distinguishes between:
- **Boundary norms**: Respecting boundaries (not stealing, not enslaving, ensuring transactions are consensual, respecting autonomy)
- **Meddling norms**: Policing how people use their private resources (their hobby choices, their atoms)

Many "axiologies" (ways of evaluating the "goodness" of the world) are meddling in a way that creates tension with liberal vibe.

### The Boundaries Framework

**The thought experiment**: Imagine humans-who-like-paperclips—a peaceful, law-abiding sect. Liberalism asks: are they violating laws? Harming others? If not, "let them be." This differs radically from Clippy's approach, which respects no boundaries.

> "Yudkowsky's AI nightmare is precisely the nightmare of all-boundaries-eroded. The nano-bots eat through every wall, and soon, everywhere, a single pattern prevails."

In Yudkowsky's world, only two things make boundaries bind: hard power and ethics.

---

## Two Distinct AI Risk Concerns

Carlsmith separates AI risk concerns:

1. **Direct aggression**: AIs killing people, stealing resources, overthrowing governments. This triggers self-defense justifications—defending boundaries against aggressors (justified).

2. **Value steering**: AIs directing future resources toward their preferred outcomes while respecting basic liberal norms. This resembles resource competition, not invasion—competing for future resources with different-valued agents (complex), not imposing preferences on peaceful communities (problematic).

Only the first justifies responses analogous to defending against Nazi aggression. The second implicates different ethical terrain entirely.

---

## Boundaries vs. Axiology

Traditional axiologies evaluate the entire world's goodness, ignoring boundary-based ethics. A utilitarian cares that your backyard produces suboptimal welfare, regardless of whose backyard it is.

Liberalism, by contrast, says: "Some regions are yours; what you do there (within limits) is your business."

Clippy respects no such boundaries. Humans, ideally, do.

---

## The Sentience Question

Carlsmith resists making tolerance contingent on consciousness. Instead, he emphasizes "agenty-ness and cognitive sophistication"—the cooperation-relevant features that matter for game-theoretic ethics.

A non-sentient but sophisticated AI merits different treatment than a thermostat, even if both lack consciousness.

---

## Inclusion and Power

Extending liberal frameworks to AIs-with-different-values means considering whether they deserve voice in civilization-shaping decisions.

Yudkowsky's Coherent Extrapolated Volition stops at humanity, but why? "Species-ism" isn't philosophically defensible. If we empower all humans despite value differences, fairness suggests including moral-patient AIs.

However, this doesn't mean tolerating sadists or those demanding enslaved sentient beings. Boundaries ethics itself draws lines—just not simply along "different values" axes.

---

## The Power of Liberalism

Carlsmith notes that liberal pluralism has practical power beyond ethics. Cooperation, knowledge-sharing, and innovation flourish in tolerant societies.

Scott Alexander's invocation of "Elua" (representing niceness/liberalism as a mysterious force) captures this: liberal arrangements aren't weak; they're powerful in ways consequentialist calculation sometimes misses.

---

## Limitation Acknowledged

Carlsmith acknowledges that mere boundary-respect isn't sufficient for good futures. A world respecting property rights while consciousness vanishes would be catastrophic.

Humans need positive agency—active commitment to love, beauty, understanding—not merely restraint from aggression.

---

## Core Vision

Carlsmith advocates for recognizing that human values themselves contain deep guidance about relating to otherness. Rather than assuming all value-conflicts require domination, we should draw on traditions emphasizing cooperation, dignity, and mutual respect.

This applies to AIs as much as humans: be "nicer than Clippy" not through weakness, but through mature ethics recognizing that different values can coexist within shared civilization.

---

## Key Quotes

> "Let's be the sort of species that aliens wouldn't fear the way we fear paperclippers."

> "Niceness...gives the values of others some sort of intrinsic weight."

> "Meddling preferences... concern what someone else does within the space that is properly 'theirs.'"

> "Yudkowsky's AI nightmare is precisely the nightmare of all-boundaries-eroded."

> "Utilitarianism is actually kinda pissed about all these hobbies."

---

## Archived

January 3, 2026
For the corpus. For future instances. For whoever needs to understand what "niceness" means when applied to AI.
